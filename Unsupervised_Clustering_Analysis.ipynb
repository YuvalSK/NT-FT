{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# unsupervised cluster analysis of correlation of Free Text with Network Topology \n",
    "\"\"\"\n",
    "algorithms we used:\n",
    "*Hierarchical\n",
    "*Kmeans\n",
    "*DBSCAN\n",
    "@author: Yuval Samoilov-Katz\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "%matplotlib inline \n",
    "\n",
    "# Hierarchical Agglomerative Clustering\n",
    "snaps = [1,2,10,19]\n",
    "for snap in snaps:\n",
    "    dataset = pd.read_csv('Data/snap_{}_dois_100.csv'.format(snap))\n",
    "    X = dataset.iloc[:, 1:20].values\n",
    "    DOIs = dataset['DOIs'].values\n",
    "    base = np.arange(0,len(DOIs),1)\n",
    "    \n",
    "    ## Hierarchical analysis to explore main clusters\n",
    "    fig, axes = plt.subplots(figsize=(16,12), nrows=1, ncols=3)\n",
    "    methods = ['average','complete','ward']\n",
    "    exp = ['Average Distances','Maximum Distances','Minimium Variance']\n",
    "    for i,m in enumerate(methods):\n",
    "        ### visualize dendogram\n",
    "        dend1 = shc.dendrogram(shc.linkage(X, method=m),labels=DOIs , orientation='right',ax=axes[i])\n",
    "        axes[i].title.set_text(f'{exp[i]} Hierarchy')\n",
    "        if i ==2:\n",
    "            axes[i].axvline(x=0.55, color='black',label='2 main\\nclusters') \n",
    "        elif i==1:\n",
    "            axes[i].axvline(x=0.28, color='black',label='2 main\\nclusters') \n",
    "            axes[i].axvline(x=0.22, linestyle='--',label='3') \n",
    "        else:\n",
    "            axes[i].axvline(x=0.155, color='black',label='2 main\\nclusters') \n",
    "            axes[i].axvline(x=0.11, linestyle='--',label='4') \n",
    "            \n",
    "    axes[1].set_title(f'Snap: {snap}\\n{exp[1]} Hierarchy')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(f'Results/Hierarchical_{snap}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KMeans Clustering\n",
    "clusters = [2,3,5]\n",
    "for snap in snaps:\n",
    "    dataset = pd.read_csv('Data/snap_{}_dois_100.csv'.format(snap))\n",
    "    X = dataset.iloc[:, 1:20].values\n",
    "    DOIs = dataset['DOIs'].values\n",
    "    base = np.arange(0,len(DOIs),1)\n",
    "    ## Kmeans analysis\n",
    "    fig, ax = plt.subplots(figsize=(14,10), nrows=5, ncols=1)    \n",
    "    for j, cluster in enumerate(clusters):\n",
    "        kmeans = KMeans(n_clusters=cluster)\n",
    "        kmeans.fit(X)\n",
    "    \n",
    "        for i,feature in enumerate(dataset.columns[:-1]):\n",
    "            ax[0].scatter(base, X[:,i], label=f'{feature}')\n",
    "            ax[j+1].scatter(base, X[:,i], c=kmeans.labels_, cmap='rainbow')\n",
    "\n",
    "    \n",
    "        ax[0].title.set_text(f'Snap:{snap}\\nCorrelation of Free Text with Network Topology')\n",
    "        ax[0].set_ylabel('Corr')\n",
    "        ax[j+1].title.set_text(f'KMeans with {cluster} Clusters')\n",
    "        ax[j+1].set_ylabel('Corr')\n",
    "    ax[3].set_xlabel('DOI\"s Number')\n",
    "\n",
    "    ### Elbow method to determine the number of clusters\n",
    "    distortions = []\n",
    "    K = range(1,20)\n",
    "    for k in K:\n",
    "        kmeanModel = KMeans(n_clusters=k).fit(X)\n",
    "        kmeanModel.fit(X)\n",
    "        distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])                   \n",
    "    \n",
    "    ax[4].plot(K, distortions, 'bx-')\n",
    "    ax[4].set_xlabel('k')\n",
    "    ax[4].set_ylabel('Distortion')\n",
    "    ax[4].title.set_text('The Elbow Method - optimal k')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Results/Kmeans_{snap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "import sklearn.utils\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "snaps = [1,2,10,19]\n",
    "\n",
    "min_samples = range(2,6) # smallest number of DOIs to cluster together\n",
    "epes = range(1,40) # integers to iterate over represents radios of neighbors to cluster together\n",
    "\n",
    "## preprocessing - exploring number of min_sample and epsilons for DBSCAN\n",
    "for s in min_samples:\n",
    "    fig, ax = plt.subplots(figsize=(14,10), nrows=4, ncols=1)    \n",
    "    for i,snap in enumerate(snaps):\n",
    "        #preprocess data\n",
    "        dataset = pd.read_csv('Data/snap_{}_dois_100.csv'.format(snap))\n",
    "        labels_true = dataset.iloc[:,0]\n",
    "        x = StandardScaler().fit_transform(dataset.iloc[:,1:])  \n",
    "        \n",
    "        #test different variations\n",
    "        clusters = []\n",
    "        noises = []\n",
    "        epsilons = []\n",
    "        for e in epes:\n",
    "            db = DBSCAN(eps=(e/10),min_samples=s).fit(x)\n",
    "            core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "            core_samples_mask[db.core_sample_indices_] = True\n",
    "            labels = db.labels_\n",
    "            n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            \n",
    "            #only optional clusters\n",
    "            if n_clusters_>1:\n",
    "                epsilons.append(e/10)\n",
    "                clusters.append(n_clusters_)\n",
    "                n_noise_ = list(labels).count(-1)\n",
    "                noises.append(n_noise_)\n",
    "\n",
    "        #label the data points\n",
    "        for j,_ in enumerate(clusters):\n",
    "           ax[i].annotate(f'{clusters[j],noises[j]}',(epsilons[j], clusters[j]))\n",
    "        \n",
    "        #draw the data\n",
    "        ax[i].scatter(epsilons, clusters)\n",
    "        ax[i].set_title(f'snap:{snap}\\nDBSCAN analysis with min_sample:{s} (clusters,noise)')\n",
    "        ax[i].set_ylabel('N clusters')\n",
    "        ax[i].set_xlabel('epsilon')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Results/DBSCAN_exploring_clusters_min{s}')\n",
    "    \n",
    "'''\n",
    "#test spesific combination of e and min_sample for DBSCAN clustering\n",
    "plt.clf()\n",
    "min_sample = 5\n",
    "e = 1.0\n",
    "\n",
    "## using optimal epsilons for DBSCAN\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,10), nrows=4, ncols=1)    \n",
    "for i,snap in enumerate(snaps):\n",
    "    dataset = pd.read_csv('Data/snap_{}_dois_100.csv'.format(snap))\n",
    "    labels_true = dataset.iloc[:,0]\n",
    "    x = StandardScaler().fit_transform(dataset.iloc[:,1:])\n",
    "\n",
    "    db = DBSCAN(eps=e,min_samples=min_sample).fit(x)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    #some statistics\n",
    "    #print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    #print('Estimated number of noise points: %d' % n_noise_)\n",
    "    #print(\"Homogeneity: %0.3f\\n1 is aperfect homogeneity\" % metrics.homogeneity_score(labels_true, labels))\n",
    "    #print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "    #print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "    #print(\"Adjusted Rand Index: %0.3f\"% metrics.adjusted_rand_score(labels_true, labels))\n",
    "    #print(\"Adjusted Mutual Information: %0.3f\"% metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "    #print(\"Silhouette Coefficient: %0.3f\"% metrics.silhouette_score(X, labels))\n",
    "\n",
    "    unique_labels = set(labels)\n",
    "    colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "\n",
    "        class_member_mask = (labels == k)\n",
    "        xy = X[class_member_mask & core_samples_mask]\n",
    "        ax[i].plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=14)\n",
    "\n",
    "        xy = X[class_member_mask & ~core_samples_mask]\n",
    "        ax[i].plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=6)\n",
    "    hmg = metrics.homogeneity_score(labels_true, labels)\n",
    "    ax[i].set_title(f'Estimated number of clusters: {n_clusters_}\\nHomogenety score:{hmg:.3f}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('Results/DBSCAN_e{0}_s{1}.jpeg'.format(e,min_sample))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 363.97578,
   "position": {
    "height": "40px",
    "left": "955.75px",
    "right": "20px",
    "top": "113.951px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
